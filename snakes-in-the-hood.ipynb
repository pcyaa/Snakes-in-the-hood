{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2021-09-10T10:21:44.704505Z","iopub.execute_input":"2021-09-10T10:21:44.70484Z","iopub.status.idle":"2021-09-10T10:21:55.652184Z","shell.execute_reply.started":"2021-09-10T10:21:44.70481Z","shell.execute_reply":"2021-09-10T10:21:55.651276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nfrom skimage import io, transform\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import OrderedDict","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-09-10T10:21:55.664124Z","iopub.execute_input":"2021-09-10T10:21:55.664363Z","iopub.status.idle":"2021-09-10T10:21:57.69829Z","shell.execute_reply.started":"2021-09-10T10:21:55.664338Z","shell.execute_reply":"2021-09-10T10:21:57.697539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:21:57.699631Z","iopub.execute_input":"2021-09-10T10:21:57.69996Z","iopub.status.idle":"2021-09-10T10:21:57.764136Z","shell.execute_reply.started":"2021-09-10T10:21:57.699924Z","shell.execute_reply":"2021-09-10T10:21:57.763196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/hackerearths-snakes-in-the-hood/dataset/train.csv')\nprint(data.head())\ndata.breed.value_counts()\n#print(data.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:21:57.765526Z","iopub.execute_input":"2021-09-10T10:21:57.766105Z","iopub.status.idle":"2021-09-10T10:21:57.802411Z","shell.execute_reply.started":"2021-09-10T10:21:57.766066Z","shell.execute_reply":"2021-09-10T10:21:57.801452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(data.breed)\nlabels = le.transform(data.breed)\ndata['labels'] = pd.DataFrame(labels)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:21:57.805641Z","iopub.execute_input":"2021-09-10T10:21:57.805988Z","iopub.status.idle":"2021-09-10T10:21:57.921852Z","shell.execute_reply.started":"2021-09-10T10:21:57.805951Z","shell.execute_reply":"2021-09-10T10:21:57.920905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n\n    def __init__(self, data, root_dir):\n        self.data = data\n        self.root_dir = root_dir\n        self.transform = transforms.Compose([transforms.ToPILImage(), \n                                transforms.Resize((256, 256)),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.RandomVerticalFlip(),\n                                transforms.RandomRotation(60),\n                                transforms.RandomRotation(20),\n#                                 transforms.RandomRotation(120),\n#                                 transforms.ColorJitter(),\n                                transforms.RandomCrop(256, padding=32),\n                                transforms.ToTensor()])\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n\n        img_name = os.path.join(self.root_dir,\n                                self.data.iloc[idx, 0]+'.jpg')\n        image = io.imread(img_name)\n        image = self.transform(image)\n        labels = self.data.iloc[idx, 2]\n        labels = np.array([labels])\n        #sample = {'images': image, 'labels': labels}\n\n        return (image, labels)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:21:57.923807Z","iopub.execute_input":"2021-09-10T10:21:57.924156Z","iopub.status.idle":"2021-09-10T10:21:57.934274Z","shell.execute_reply.started":"2021-09-10T10:21:57.924121Z","shell.execute_reply":"2021-09-10T10:21:57.933344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = CustomDataset(data = data,\n                        root_dir='../input/hackerearths-snakes-in-the-hood/dataset/train')\n\nlen(data)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:21:57.935633Z","iopub.execute_input":"2021-09-10T10:21:57.936295Z","iopub.status.idle":"2021-09-10T10:21:57.946576Z","shell.execute_reply.started":"2021-09-10T10:21:57.936253Z","shell.execute_reply":"2021-09-10T10:21:57.945917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_count = len(data)\n\ntrain_count = int(0.8 * total_count) \ntest_count = total_count - train_count\n\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, (train_count, test_count))\n\ntrain_dataset_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)  \ntest_dataset_loader  = torch.utils.data.DataLoader(test_dataset , batch_size=64, shuffle=False)\ndataloaders = {'train': train_dataset_loader, 'test': test_dataset_loader}","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:21:57.94828Z","iopub.execute_input":"2021-09-10T10:21:57.948684Z","iopub.status.idle":"2021-09-10T10:21:57.969376Z","shell.execute_reply.started":"2021-09-10T10:21:57.948646Z","shell.execute_reply":"2021-09-10T10:21:57.968558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:21:57.970576Z","iopub.execute_input":"2021-09-10T10:21:57.970924Z","iopub.status.idle":"2021-09-10T10:21:57.976748Z","shell.execute_reply.started":"2021-09-10T10:21:57.970888Z","shell.execute_reply":"2021-09-10T10:21:57.975832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class CNN(nn.Module):\n#     def __init__(self):\n#         super(CNN, self).__init__()\n        \n#         self.cnn1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, stride = 1, padding = 1)\n#         self.batchnorm1 = nn.BatchNorm2d(8)\n#         self.relu = nn.ReLU()\n#         self.maxpool = nn.MaxPool2d(kernel_size = 2)\n        \n#         self.cnn2 = nn.Conv2d(in_channels = 8, out_channels = 32, kernel_size = 5, stride = 1, padding = 2)\n#         self.batchnorm2 = nn.BatchNorm2d(32)\n        \n#         self.cnn3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 5, stride = 1, padding = 2)\n#         self.batchnorm3 = nn.BatchNorm2d(64)\n        \n#         self.cnn4 = nn.Conv2d(in_channels = 64, out_channels = 256, kernel_size = 5, stride = 1, padding = 2)\n#         self.batchnorm4 = nn.BatchNorm2d(256)\n        \n#         self.dropout = nn.Dropout(p = 0.7)\n#         self.fc1 = nn.Linear(256*256, 2000)\n#         self.fc2 = nn.Linear(2000, 1000)\n#         self.fc3 = nn.Linear(1000, 350)\n        \n#     def forward(self, x):\n#         out = self.cnn1(x)\n#         out = self.batchnorm1(out)\n#         out = self.relu(out)\n#         out = self.maxpool(out)\n        \n#         out = self.cnn2(out)\n#         out = self.batchnorm2(out)\n#         out = self.relu(out)\n#         out = self.maxpool(out)\n        \n#         out = self.cnn3(out)\n#         out = self.batchnorm3(out)\n#         out = self.relu(out)\n#         out = self.maxpool(out)\n        \n#         out = self.cnn4(out)\n#         out = self.batchnorm4(out)\n#         out = self.relu(out)\n#         out = self.maxpool(out)\n        \n#         out = out.view(-1, 256*256)\n        \n#         out = self.fc1(out)\n#         out = self.relu(out)\n#         out = self.dropout(out)\n        \n#         out = self.fc2(out)\n#         out = self.relu(out)\n#         out = self.dropout(out)\n        \n#         out = self.fc3(out)\n#         return out","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:21:57.978183Z","iopub.execute_input":"2021-09-10T10:21:57.978748Z","iopub.status.idle":"2021-09-10T10:21:57.985083Z","shell.execute_reply.started":"2021-09-10T10:21:57.97871Z","shell.execute_reply":"2021-09-10T10:21:57.983954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\n\ndef train():\n    model.train()\n    all_pred = []\n    all_labels = []\n    tk0 = tqdm(train_dataset_loader, total=int(len(train_dataset_loader)))\n    scheduler.step()\n    \n    for inputs, labels in tk0:\n        inputs = inputs.to(device, dtype=torch.float)\n        labels = labels.to(device, dtype=torch.float)\n\n        outputs = model(inputs)\n        optimizer.zero_grad()\n        loss = criterion(outputs, labels.squeeze())\n        loss.backward()\n        optimizer.step()\n\n        _, predicted = torch.max(outputs, 1)\n        all_pred.append(predicted.tolist())\n        all_labels.append(labels.tolist())\n\n    flat_pred = np.array([item for sublist in all_pred for item in sublist])\n    flat_labels = np.array([item for sublist in all_labels for item in sublist])\n    \n    print('For epoch {}/{}, training fscore = {:.3f}'.format(epoch+1, epochs, f1_score(flat_pred, flat_labels, average = 'weighted')))\n        \ndef eval():\n    model.eval()\n    all_pred = []\n    all_labels = []\n\n    tk0 = tqdm(test_dataset_loader, total=int(len(test_dataset_loader)))\n    \n    for inputs, labels in tk0:\n        inputs = inputs.to(device, dtype=torch.float)\n        labels = labels.to(device, dtype=torch.float)\n        \n        outputs = model(inputs)\n#         optimizer.zero_grad()\n#         loss = criterion(outputs, labels.squeeze())\n#         loss.backward()\n#         optimizer.step()\n\n        _, predicted = torch.max(outputs, 1)\n        all_pred.append(predicted.tolist())\n        all_labels.append(labels.tolist())\n\n    flat_pred = np.array([item for sublist in all_pred for item in sublist])\n    flat_labels = np.array([item for sublist in all_labels for item in sublist])\n\n    print('For epoch {}/{}, testing fscore = {:.3f}'.format(epoch+1, epochs, f1_score(flat_pred, flat_labels, average = 'weighted')))\n            \ndef predict():\n    \n    model.eval()\n    all_pred = []\n    all_labels = []\n    \n    for inputs, labels in test_set_loader:\n        inputs = inputs.to(device, dtype=torch.float)\n\n        outputs = model(inputs)\n\n        _, predicted = torch.max(outputs, 1)\n        all_pred.append(predicted.tolist())\n\n    flat_pred = np.array([item for sublist in all_pred for item in sublist])\n    return falt_pred","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:21:57.98648Z","iopub.execute_input":"2021-09-10T10:21:57.987084Z","iopub.status.idle":"2021-09-10T10:21:58.034699Z","shell.execute_reply.started":"2021-09-10T10:21:57.987032Z","shell.execute_reply":"2021-09-10T10:21:58.033944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\nmodel = models.densenet121(pretrained = True)\nnum_classes = 350\n\n# for param in model.parameters():\n#     param.requires_grad = False \n# num_ftrs = model.fc.in_features\n# fc = nn.Sequential(OrderedDict([\n#     ('fc1', nn.Linear(num_ftrs,1000)),\n#     ('relu', nn.ReLU()),\n#     ('fc2', nn.Linear(1000, 350)),\n#     ('output', nn.LogSoftmax(dim=1))\n# ]))\n# model.fc = fc\n\n# num_ftrs = model.fc.in_features\n# model.fc = nn.Linear(num_ftrs, num_classes)\n\n# model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n\nmodel.classifier = nn.Linear(1024, num_classes)\n\n# model = CNN()\n\nmodel.to(device, dtype=torch.float)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma = 0.1)\n\n\nepochs = 35\n\nfor epoch in range(epochs):\n    train()\n    eval()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:21:58.035922Z","iopub.execute_input":"2021-09-10T10:21:58.036373Z","iopub.status.idle":"2021-09-10T10:22:04.073042Z","shell.execute_reply.started":"2021-09-10T10:21:58.036334Z","shell.execute_reply":"2021-09-10T10:22:04.070972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/hackerearths-snakes-in-the-hood/dataset/test.csv')\ntest['labels2'] = 1\ntest['labels'] = 1\nprint(test.head())\n\ntest_set = CustomDataset(data = test,\n                         root_dir='../input/hackerearths-snakes-in-the-hood/dataset/test')\n\ntest_set_loader  = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:22:04.074306Z","iopub.status.idle":"2021-09-10T10:22:04.075077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_pred = []\nall_labels = []\n\nfor inputs, labels in test_set_loader:\n    inputs = inputs.to(device, dtype=torch.float)\n\n    outputs = model(inputs)\n\n    _, predicted = torch.max(outputs, 1)\n    all_pred.append(predicted.tolist())\n\nflat_pred = np.array([item for sublist in all_pred for item in sublist])","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:22:04.076416Z","iopub.status.idle":"2021-09-10T10:22:04.077126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ans=pd.DataFrame((zip(test['image_id'], flat_pred)), columns=['image_id','breed'])","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:22:04.078363Z","iopub.status.idle":"2021-09-10T10:22:04.079084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ans['breed'] = le.inverse_transform(ans['breed'])","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:22:04.08039Z","iopub.status.idle":"2021-09-10T10:22:04.08108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ans.to_csv('output.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T10:22:04.082513Z","iopub.status.idle":"2021-09-10T10:22:04.083248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}